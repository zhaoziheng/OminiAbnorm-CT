# Experiment Settings
exp_name: 'Exp_Name'

# Vis Prompt Gen Task
train_data_json: 'OminiAbnormCT_14K/merged_train.json'
rewritten_max: 3
allow_multi_prompt: true
vis_prmpt_gen_epoch_quota: 50000

# Grounding Task
deeplesion_json: null # '/DeepLesion/train.json'
radiopedia_json: 'OminiAbnormCT_14K/merged_train.json'
other_data_json: null # 'other_datasets_train.json'
deeplesion_weight: 0.0
radiopedia_weight: 1.0
other_data_weight: 0.0
grounding_epoch_quota: 0

# Refer Grounding Task
negative_refer_ratio: 0.5
refer_grounding_epoch_quota: 50000

# Grounding Gen Task
grounding_gen_epoch_quota: 50000

# Instruction QA Task
pubmedvision_json: null # 'PubMedVision/PubMedVision_InstructionTuning_VQA.json'
instruction_qa_epoch_quota: 0

# Model Settings
model_path: 'Qwen/Qwen2.5-VL-7B-Instruct'
adapter_path: './checkpoints/ominiabnorm-ct-7b'
tokenizer_path: './checkpoints/ominiabnorm-ct-7b/extended_tokenizer'
lora_rank: 32
other_trainable_param_path: './checkpoints/ominiabnorm-ct-7b/seg_model_lm_head_embed_tokens.pt'
forzen_seg_model: 'none'

# Training Settings
epochs: 20
logging_steps: 1000
eval_steps: 1000
save_steps: 2000
per_device_batch_size: 1
gradient_accumulation_steps: 4
gradient_checkpointing: true